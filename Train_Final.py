import os
import torch
import torchaudio
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
from tqdm import tqdm
import shutil
from cnn import CNNNetwork10
from AudioAugmentation import CombinedAugmentation
from Emotionsounddataset import EmotionSoundDataset
from sklearn.model_selection import train_test_split

# ==================== ÈÖçÁΩÆÂèÇÊï∞ ====================
class Config:
    # ËÆæÂ§áÈÖçÁΩÆ
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    # ËÆ≠ÁªÉÂèÇÊï∞
    BATCH_SIZE = 64
    EPOCHS = 120
    LEARNING_RATE = 1e-3
    WEIGHT_DECAY = 1e-4
    PATIENCE = 10
    
    # Èü≥È¢ëÂèÇÊï∞
    SAMPLE_RATE = 22050
    NUM_SAMPLES = SAMPLE_RATE * 10  # 10ÁßíÈü≥È¢ë
    
    # Â≠¶‰π†ÁéáË∞ÉÂ∫¶
    WARMUP_RATIO = 0.1
    MAX_LR_FACTOR = 1.5
    INIT_DIV_FACTOR = 25
    FINAL_DIV_FACTOR = 1e4
    
    # Ë∑ØÂæÑÈÖçÁΩÆ
    BEST_MODEL_PATH = "best_emotion_classifier_amp_enhanced_11.pth"
    ANNOTATIONS_FILE = r"C:\Users\14217\Desktop\DT2470\Predictions with sound classifier\metadata_balanced_10s_multi.tsv"
    AUDIO_DIR = r"C:\Users\14217\Desktop\DT2470\Predictions with sound classifier"
    PRECOMPUTE_DIR = os.path.join(AUDIO_DIR, "precomputed")
    
    # Ê†áÁ≠æÈÖçÁΩÆ
    TOP10_TAGS = [
        'melodic', 
        'energetic', 
        'dark', 
        'film', 
        'relaxing',
        'dream', 
        'ambiental', 
        'love', 
        'soundscape', 
        'emotional'
    ]

# ==================== È¢ÑËÆ°ÁÆóÊ®°Âùó ====================
class FeaturePrecomputer:
    """ÁâπÂæÅÈ¢ÑËÆ°ÁÆóÂô®"""
    
    @staticmethod
    def precompute_features(dataset, save_dir, suffix=""):
        """È¢ÑËÆ°ÁÆóÁâπÂæÅÔºàÂ¢ûÂº∫ÂÆåÂÖ®Áî±Êï∞ÊçÆÈõÜÁ±ªÊéßÂà∂Ôºâ"""
        features = []
        labels = []
        
        # Áõ¥Êé•‰ªéÊï∞ÊçÆÈõÜËé∑ÂèñÂ¢ûÂº∫Áä∂ÊÄÅ
        augment_info = dataset.get_dataset_info()
        print(f"üîß È¢ÑËÆ°ÁÆóÁâπÂæÅ | Èü≥È¢ëÂ¢ûÂº∫: {augment_info['audio_augment']} | È¢ëË∞±Â¢ûÂº∫: {augment_info['spec_augment']}")
        
        for i in tqdm(range(len(dataset))):
            try:
                # üéØ ÁÆÄÂåñÔºöÁõ¥Êé•‰ΩøÁî®Ê†áÂáÜÊé•Âè£ÔºåËÆ©Êï∞ÊçÆÈõÜÂ§ÑÁêÜÊâÄÊúâÂ¢ûÂº∫ÈÄªËæë
                mel, label = dataset[i]
                
                # Á°Æ‰øùÊ≠£Á°ÆÁöÑÁª¥Â∫¶
                if mel.ndim == 2:
                    mel = mel.unsqueeze(0)
                elif mel.ndim == 3 and mel.shape[0] != 1:
                    mel = mel.mean(0, keepdim=True)
                
                # detach() ÁßªÈô§Ê¢ØÂ∫¶‰ø°ÊÅØ, numpy()ËΩ¨Êç¢‰∏∫ÂèØ‰øùÂ≠òÊ†ºÂºè, cpu()ÊúÄÁªàËΩ¨ËΩΩ‰ΩçÁΩÆ
                # ‰øùÁïôÈ¢ÑËÆ°ÁÆóÁâπÂæÅ,ÂêéÁª≠Êñπ‰æøË∞ÉÁî®
                features.append(mel.cpu().detach().numpy())  # Ê∑ªÂä† .detach()
                labels.append(label)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Ë∑≥ËøáÊ†∑Êú¨ {i}: {e}")
                continue
            
        # ‰øùÂ≠òÁâπÂæÅ
        features_array = np.stack(features).astype(np.float32)
        labels_array = np.array(labels)
    
        features_path = os.path.join(save_dir, f"features_{suffix}.npy")
        labels_path = os.path.join(save_dir, f"labels_{suffix}.npy")
        
        np.save(features_path, features_array)
        np.save(labels_path, labels_array)
        
        print(f"‚úÖ È¢ÑËÆ°ÁÆóÂÆåÊàê: {len(features_array)} Ê†∑Êú¨")
        return features_path, labels_path
    

# ==================== Êï∞ÊçÆÈõÜÁ±ª ====================
class PrecomputedTrainDataset(Dataset):
    """
    È¢ÑËÆ°ÁÆóËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºàÂåÖÂê´ÂÆûÊó∂È¢ëË∞±Â¢ûÂº∫Ôºâ
    """
    
    def __init__(self, features, labels, device):  # üéØ ‰øÆÂ§çÔºöÁõ¥Êé•‰º†ÂÖ•Êï∞ÁªÑ
        self.features = features
        self.labels = labels
        self.device = device
        # üéØ ËÆ≠ÁªÉÊó∂Â∫îÁî®È¢ëË∞±Â¢ûÂº∫
        self.augmentor = CombinedAugmentation(
            sample_rate=Config.SAMPLE_RATE, 
            device=device,
            deterministic=False,  # ËÆ≠ÁªÉÊó∂Áî®ÈöèÊú∫Â¢ûÂº∫
            audio_augment=False,
            spec_augment=True     # ÊòéÁ°ÆÂêØÁî®È¢ëË∞±Â¢ûÂº∫
        )
        
        print(f"üìä Âä†ËΩΩÈ¢ÑËÆ°ÁÆóËÆ≠ÁªÉÁâπÂæÅ: {self.features.shape}")

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        x = torch.tensor(self.features[idx], dtype=torch.float32)
        
        # Á°Æ‰øùËæìÂÖ•ÊòØ3D: [1, n_mels, time]
        x = self._ensure_3d(x)
        
        # üéØ Â∫îÁî®È¢ëË∞±Â¢ûÂº∫ÔºàÂú®GPU‰∏äÔºâ
        x = self.augmentor(x)
        
        y = int(self.labels[idx])
        return x, y
    
    def _ensure_3d(self, x):
        """Á°Æ‰øùËæìÂÖ•‰∏∫3DÂº†Èáè"""
        if x.ndim == 4:
            if x.shape[0] == 1 and x.shape[1] == 1:
                x = x.squeeze(0)
            else:
                x = x[0]
        if x.ndim == 2:
            x = x.unsqueeze(0)
        return x

class PrecomputedEvalDataset(Dataset):
    """È¢ÑËÆ°ÁÆóËØÑ‰º∞Êï∞ÊçÆÈõÜÔºàÊó†Â¢ûÂº∫Ôºâ"""
    
    def __init__(self, features, labels, device):  # üéØ ‰øÆÂ§çÔºöÁõ¥Êé•‰º†ÂÖ•Êï∞ÁªÑ
        self.features = features
        self.labels = labels
        self.device = device
        print(f"üìä Âä†ËΩΩÈ¢ÑËÆ°ÁÆóËØÑ‰º∞ÁâπÂæÅ: {self.features.shape}")

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        x = torch.tensor(self.features[idx], dtype=torch.float32)
        x = self._ensure_3d(x)
        y = int(self.labels[idx])
        return x, y
    
    def _ensure_3d(self, x):
        """Á°Æ‰øùËæìÂÖ•‰∏∫3DÂº†Èáè"""
        if x.ndim == 4:
            if x.shape[0] == 1 and x.shape[1] == 1:
                x = x.squeeze(0)
            else:
                x = x[0]
        if x.ndim == 2:
            x = x.unsqueeze(0)
        return x

# ==================== Êï∞ÊçÆÂä†ËΩΩÂô® ====================
class DataLoaderFactory:
    """Êï∞ÊçÆÂä†ËΩΩÂô®Â∑•ÂéÇ"""
    
    @staticmethod
    def create_loader(dataset, batch_size, shuffle=True):
        return DataLoader(
            dataset, 
            batch_size=batch_size, 
            shuffle=shuffle, 
            drop_last=True, 
            num_workers=0,  # ÂçïËøõÁ®ã
            pin_memory=True  # Âä†ÈÄüGPUÊï∞ÊçÆ‰º†Ëæì
        )

# ==================== ËÆ≠ÁªÉÊ®°Âùó ====================
class ModelTrainer:
    """Ê®°ÂûãËÆ≠ÁªÉÂô®"""
    
    def __init__(self, model, train_loader, val_loader, test_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.device = Config.DEVICE
        
    def train_single_epoch(self, criterion, optimizer, scaler, scheduler, epoch_desc):
        """ËÆ≠ÁªÉÂçï‰∏™epoch"""

        # PyTorchÁöÑÂàáÊç¢Âà∞ËÆ≠ÁªÉÁöÑÊåá‰ª§
        self.model.train()
        total_loss, correct, total = 0, 0, 0
        
        batch_pbar = tqdm(self.train_loader, desc=epoch_desc, leave=False)

        for batch_idx, (x, y) in enumerate(batch_pbar):
            x = x.to(self.device, non_blocking=True)
            y = y.to(self.device, non_blocking=True)
            
            optimizer.zero_grad()
            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):
                pred = self.model(x)
                loss = criterion(pred, y)
            
            # mixed precision grad management
            scaler.scale(loss).backward()   # grad squeeze -> transfer(auto finish in GPU)
            scaler.step(optimizer)          # unsqueeze
            scaler.update()                 # update
            
            # Â≠¶‰π†ÁéáË∞ÉÂ∫¶
            if scheduler is not None:
                current_lr = scheduler.get_last_lr()[0] 
                scheduler.step()
            
            # ÁªüËÆ°‰ø°ÊÅØ
            total_loss += loss.item()   # loss_value = loss.item()  total_loss += loss_value
            _, predicted = pred.max(dim=1)
            batch_correct = predicted.eq(y).sum().item()
            correct += batch_correct
            total += y.size(dim=0)
            
            # Êõ¥Êñ∞ËøõÂ∫¶Êù°
            batch_acc = 100 * batch_correct / y.size(0)
            current_lr = current_lr if scheduler else optimizer.param_groups[0]['lr']
            # instant print
            batch_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'BatchAcc': f'{batch_acc:.1f}%',
                'LR': f'{current_lr:.2e}'
            })
        
        return total_loss / len(self.train_loader), 100 * correct / total
    
    def validate(self, criterion):
        """È™åËØÅÊ®°Âûã"""
        self.model.eval()
        total_loss, correct, total = 0, 0, 0
        
        with torch.no_grad():
            for x, y in self.val_loader:
                x = x.to(self.device, non_blocking=True)
                y = y.to(self.device, non_blocking=True)
                
                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):
                    pred = self.model(x)
                    loss = criterion(pred, y)
                
                total_loss += loss.item()
                _, predicted = pred.max(dim=1)
                correct += predicted.eq(y).sum().item()
                total += y.size(dim=0)
        
        return total_loss / len(self.val_loader), 100 * correct / total
    
    def test(self, criterion):
        """ÊµãËØïÊ®°Âûã"""
        self.model.eval()
        total_loss, correct, total = 0, 0, 0
        
        with torch.no_grad():
            for x, y in self.test_loader:
                x = x.to(self.device, non_blocking=True)
                y = y.to(self.device, non_blocking=True)
                
                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):
                    pred = self.model(x)
                    loss = criterion(pred, y)
                
                total_loss += loss.item()
                _, predicted = pred.max(1)
                correct += predicted.eq(y).sum().item()
                total += y.size(0)
        
        return total_loss / len(self.test_loader), 100 * correct / total

    def train(self, epochs=120, patience=10):
        """ÂÆåÊï¥ËÆ≠ÁªÉÊµÅÁ®ã"""
        # ÊçüÂ§±ÂáΩÊï∞ËÆ°ÁÆó-Âü∫‰∫éÊàêÁÜüÁöÑ‰∫§ÂèâÁÜµÁêÜËÆ∫
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.AdamW(
                                    self.model.parameters(), 
                                    lr=Config.LEARNING_RATE, 
                                    weight_decay=Config.WEIGHT_DECAY
                                    )
        scaler = torch.amp.GradScaler()
        
        # Â≠¶‰π†ÁéáË∞ÉÂ∫¶Âô®
        scheduler = torch.optim.lr_scheduler.OneCycleLR(
            optimizer,
            max_lr=Config.LEARNING_RATE * Config.MAX_LR_FACTOR,
            epochs=epochs,
            steps_per_epoch=len(self.train_loader),
            pct_start=Config.WARMUP_RATIO,
            div_factor=Config.INIT_DIV_FACTOR,
            final_div_factor=Config.FINAL_DIV_FACTOR
        )

        best_acc, epochs_no_improve = 0, 0
        
        print(f"üöÄ ÂºÄÂßãËÆ≠ÁªÉ | Epochs: {epochs} | Â≠¶‰π†Áéá: {Config.LEARNING_RATE}")
        print(f"üî• ‰ΩøÁî®OneCycleLR: warmup={Config.WARMUP_RATIO*100}%")
        print(f"üéØ Â¢ûÂº∫Á≠ñÁï•: È¢ÑËÆ°ÁÆóÈü≥È¢ëÂ¢ûÂº∫ÁâπÂæÅ + ËÆ≠ÁªÉÊó∂ÂÆûÊó∂È¢ëË∞±Â¢ûÂº∫")

        epoch_pbar = tqdm(range(epochs), desc="ËÆ≠ÁªÉËøõÂ∫¶", leave=True)
        
        for epoch in epoch_pbar:
            epoch_desc = f"Epoch {epoch+1:02d}/{epochs}"
            
            # ËÆ≠ÁªÉ
            train_loss, train_acc = self.train_single_epoch(
                criterion, optimizer, scaler, scheduler, epoch_desc
            )
            
            # È™åËØÅÂíåÊµãËØï
            val_loss, val_acc = self.validate(criterion)
            test_loss, test_acc = self.test(criterion)
            
            # Êõ¥Êñ∞ËøõÂ∫¶Êù°
            current_lr = scheduler.get_last_lr()[0]
            epoch_pbar.set_postfix({
                'Train': f'{train_acc:.1f}%',
                'Val': f'{val_acc:.1f}%', 
                'Test': f'{test_acc:.1f}%',
                'LR': f'{current_lr:.2e}'
            })
            
            # ÊâìÂç∞ËØ¶ÁªÜÁªìÊûú
            print(f"\nEpoch {epoch+1:02d}: Train {train_acc:.2f}% | Val {val_acc:.2f}% | Test {test_acc:.2f}% | LR {current_lr:.2e} | LOSS {train_loss:.4f}")
            
            # ‰øùÂ≠òÊúÄ‰Ω≥Ê®°Âûã
            if val_acc > best_acc:
                best_acc = val_acc
                epochs_no_improve = 0
                torch.save(self.model.state_dict(), Config.BEST_MODEL_PATH)
                print(f"üíæ ‰øùÂ≠òÊúÄ‰Ω≥Ê®°Âûã | Val Acc: {best_acc:.2f}%")
            else:
                epochs_no_improve += 1
                if epochs_no_improve >= patience:
                    print(f"üõë Êó©ÂÅúËß¶Âèë | ÊúÄ‰Ω≥È™åËØÅÂáÜÁ°ÆÁéá: {best_acc:.2f}%")
                    break
                
        return Config.BEST_MODEL_PATH

# ==================== ‰∏ªÁ®ãÂ∫è ====================
def main():
    # ÂàùÂßãÂåñÈÖçÁΩÆ
    print("üéØ ÂàùÂßãÂåñÈÖçÁΩÆ...")
    label_mapping = {tag: idx for idx, tag in enumerate(Config.TOP10_TAGS)}
    num_classes = len(label_mapping)
    print(f"üî¢ Ê†áÁ≠æÊò†Â∞Ñ: {label_mapping}")
    
    # Ê∏ÖÁêÜÂπ∂ÂàõÂª∫È¢ÑËÆ°ÁÆóÁõÆÂΩï
    if os.path.exists(Config.PRECOMPUTE_DIR):
        shutil.rmtree(Config.PRECOMPUTE_DIR)
        print("üóëÔ∏è Â∑≤Âà†Èô§ÊóßÁöÑÈ¢ÑËÆ°ÁÆóÊñá‰ª∂")
    os.makedirs(Config.PRECOMPUTE_DIR, exist_ok=True)
    print("üìÅ ÂàõÂª∫Êñ∞ÁöÑÈ¢ÑËÆ°ÁÆóÁõÆÂΩï")
    
    # üéØ ÂàõÂª∫ÂÆåÊï¥Êï∞ÊçÆÈõÜÔºàÈü≥È¢ëÂ¢ûÂº∫Ôºâ
    print("üîß ÂàõÂª∫ÂÆåÊï¥Êï∞ÊçÆÈõÜ...")
    full_dataset = EmotionSoundDataset(
        annotations_file=Config.ANNOTATIONS_FILE,
        audio_dir=Config.AUDIO_DIR,
        target_sample_rate=Config.SAMPLE_RATE,
        num_samples=Config.NUM_SAMPLES,
        device='cpu',
        use_log_mel=True,
        top_n_classes=10,
        augment=True,                            # ‚úÖ ÂêØÁî®Â¢ûÂº∫ÊÄªÂºÄÂÖ≥
        audio_augment=True,                      # ‚úÖ ÂêØÁî®Èü≥È¢ëÂ¢ûÂº∫
        spec_augment=False,
        deterministic_augment=True,
        augment_seed=42
    )
    
    # È¢ÑËÆ°ÁÆóÂÆåÊï¥Êï∞ÊçÆÈõÜ
    full_features_path, full_labels_path = FeaturePrecomputer.precompute_features(
        full_dataset, 
        Config.PRECOMPUTE_DIR, 
        "full"
    )

    # üéØ Âä†ËΩΩÈ¢ÑËÆ°ÁÆóÊï∞ÊçÆ
    full_features = np.load(full_features_path)
    full_labels = np.load(full_labels_path)
    print(f"üìä ÊÄªÊ†∑Êú¨Êï∞: {len(full_labels)}")

    # ÂàÜÂ±ÇÊäΩÊ†∑ÂàíÂàÜ
    print("üìä ËøõË°åÂàÜÂ±ÇÊäΩÊ†∑ÂàíÂàÜ...")
    
    # Á¨¨‰∏ÄÊ¨°ÂàíÂàÜÔºöËÆ≠ÁªÉÈõÜ vs (È™åËØÅ+ÊµãËØïÈõÜ)
    X_train, X_temp, y_train, y_temp = train_test_split(
        full_features, 
        full_labels, 
        test_size=0.3, 
        stratify=full_labels,
        random_state=42
    )
    
    # Á¨¨‰∫åÊ¨°ÂàíÂàÜÔºöÈ™åËØÅÈõÜ vs ÊµãËØïÈõÜ
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, 
        y_temp,
        test_size=0.5,
        stratify=y_temp,
        random_state=42
    )
    
    print(f"‚úÖ ÂàÜÂ±ÇÊäΩÊ†∑ÂÆåÊàê: ËÆ≠ÁªÉÈõÜ {len(y_train)} | È™åËØÅÈõÜ {len(y_val)} | ÊµãËØïÈõÜ {len(y_test)}")
    
    # üéØ ÂàõÂª∫ÊúÄÁªàÊï∞ÊçÆÈõÜ - Áõ¥Êé•‰º†ÂÖ•ÂàíÂàÜÂêéÁöÑÊï∞ÁªÑ
    print("üîß ÂàõÂª∫ÊúÄÁªàÊï∞ÊçÆÈõÜ...")
    train_dataset = PrecomputedTrainDataset(X_train, y_train, Config.DEVICE)
    val_dataset = PrecomputedEvalDataset(X_val, y_val, Config.DEVICE)
    test_dataset = PrecomputedEvalDataset(X_test, y_test, Config.DEVICE)

    print(f"üéØ ÊúÄÁªàÊï∞ÊçÆÈõÜ: ËÆ≠ÁªÉÈõÜ {len(train_dataset)} | È™åËØÅÈõÜ {len(val_dataset)} | ÊµãËØïÈõÜ {len(test_dataset)}")

    # üéØ Êï∞ÊçÆÈ™åËØÅ
    print("=== Êï∞ÊçÆÂàíÂàÜÈ™åËØÅ ===")
    print(f"ËÆ≠ÁªÉÈõÜÊ†∑Êú¨Êï∞: {len(train_dataset)}")
    print(f"È™åËØÅÈõÜÊ†∑Êú¨Êï∞: {len(val_dataset)}") 
    print(f"ÊµãËØïÈõÜÊ†∑Êú¨Êï∞: {len(test_dataset)}")
    print(f"ËÆ≠ÁªÉÈõÜÊ†áÁ≠æÂàÜÂ∏É: {np.bincount(train_dataset.labels)}")
    print(f"È™åËØÅÈõÜÊ†áÁ≠æÂàÜÂ∏É: {np.bincount(val_dataset.labels)}")
    print(f"ÊµãËØïÈõÜÊ†áÁ≠æÂàÜÂ∏É: {np.bincount(test_dataset.labels)}")

    # ÂàõÂª∫Êï∞ÊçÆÂä†ËΩΩÂô®
    train_loader = DataLoaderFactory.create_loader(train_dataset, Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoaderFactory.create_loader(val_dataset, Config.BATCH_SIZE, shuffle=False)
    test_loader = DataLoaderFactory.create_loader(test_dataset, Config.BATCH_SIZE, shuffle=False)
    
    # ÊµãËØïÊï∞ÊçÆÂΩ¢Áä∂
    for x, y in train_loader:
        print(f"üîç ËÆ≠ÁªÉÈõÜBatchÂΩ¢Áä∂: ËæìÂÖ• {x.shape} | Ê†áÁ≠æ {y.shape}")
        break
    
    # ÂàùÂßãÂåñÊ®°Âûã
    model = CNNNetwork10(num_classes=num_classes).to(Config.DEVICE)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ü§ñ ‰ΩøÁî®ÊîπËøõÁâàÊ®°Âûã | ÂèÇÊï∞Èáè: {total_params} ({total_params/1e6:.2f}M)")
    print(f"üéØ ‰ºòÂåñÊñπÊ°à: È¢ÑËÆ°ÁÆóÈü≥È¢ëÂ¢ûÂº∫ÁâπÂæÅ + ËÆ≠ÁªÉÊó∂ÂÆûÊó∂È¢ëË∞±Â¢ûÂº∫")
    
    # ÂºÄÂßãËÆ≠ÁªÉ
    trainer = ModelTrainer(model, train_loader, val_loader, test_loader)
    best_model_path = trainer.train(Config.EPOCHS, Config.PATIENCE)
    
    # ÊúÄÁªàÊµãËØï
    model.load_state_dict(torch.load(best_model_path))
    final_test_loss, final_test_acc = trainer.test(nn.CrossEntropyLoss())
    print(f"üéâ ÊúÄÁªàÊµãËØïÂáÜÁ°ÆÁéá: {final_test_acc:.2f}%")
    print(f"üíæ ÊúÄ‰Ω≥Ê®°ÂûãÂ∑≤‰øùÂ≠ò: {best_model_path}")

if __name__ == "__main__":
    main()