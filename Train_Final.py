import os
import torch
import torchaudio
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
from tqdm import tqdm
import shutil
from cnn import CNNNetwork10
from AudioAugmentation import CombinedAugmentation
from Emotionsounddataset import EmotionSoundDataset
from sklearn.model_selection import train_test_split

# ==================== é…ç½®å‚æ•° ====================
class Config:
    # è®¾å¤‡é…ç½®
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    # è®­ç»ƒå‚æ•°
    BATCH_SIZE = 64
    EPOCHS = 120
    LEARNING_RATE = 1e-3
    WEIGHT_DECAY = 1e-4
    PATIENCE = 10
    
    # éŸ³é¢‘å‚æ•°
    SAMPLE_RATE = 22050
    NUM_SAMPLES = SAMPLE_RATE * 10  # 10ç§’éŸ³é¢‘
    
    # å­¦ä¹ ç‡è°ƒåº¦
    WARMUP_RATIO = 0.1
    MAX_LR_FACTOR = 1.5
    INIT_DIV_FACTOR = 25
    FINAL_DIV_FACTOR = 1e4
    
    # è·¯å¾„é…ç½®
    BEST_MODEL_PATH = "best_emotion_classifier_amp_enhanced_11.pth"
    ANNOTATIONS_FILE = r"C:\Users\14217\Desktop\DT2470\Predictions with sound classifier\metadata_balanced_10s_multi.tsv"
    AUDIO_DIR = r"C:\Users\14217\Desktop\DT2470\Predictions with sound classifier"
    PRECOMPUTE_DIR = os.path.join(AUDIO_DIR, "precomputed")
    
    # æ ‡ç­¾é…ç½®
    TOP10_TAGS = [
        'melodic', 
        'energetic', 
        'dark', 
        'film', 
        'relaxing',
        'dream', 
        'ambiental', 
        'love', 
        'soundscape', 
        'emotional'
    ]

# ==================== é¢„è®¡ç®—æ¨¡å— ====================
class FeaturePrecomputer:
    """ç‰¹å¾é¢„è®¡ç®—å™¨"""
    
    @staticmethod
    def precompute_features(dataset, save_dir, suffix=""):
        """é¢„è®¡ç®—ç‰¹å¾ï¼ˆå¢å¼ºå®Œå…¨ç”±æ•°æ®é›†ç±»æ§åˆ¶ï¼‰"""
        features = []
        labels = []
        
        # ç›´æ¥ä»æ•°æ®é›†è·å–å¢å¼ºçŠ¶æ€
        augment_info = dataset.get_dataset_info()
        print(f"ğŸ”§ é¢„è®¡ç®—ç‰¹å¾ | éŸ³é¢‘å¢å¼º: {augment_info['audio_augment']} | é¢‘è°±å¢å¼º: {augment_info['spec_augment']}")
        
        for i in tqdm(range(len(dataset))):
            try:
                # ğŸ¯ ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨æ ‡å‡†æ¥å£ï¼Œè®©æ•°æ®é›†å¤„ç†æ‰€æœ‰å¢å¼ºé€»è¾‘
                mel, label = dataset[i]
                
                # ç¡®ä¿æ­£ç¡®çš„ç»´åº¦
                if mel.ndim == 2:
                    mel = mel.unsqueeze(0)
                elif mel.ndim == 3 and mel.shape[0] != 1:
                    mel = mel.mean(0, keepdim=True)
                
                # detach() ç§»é™¤æ¢¯åº¦ä¿¡æ¯, numpy()è½¬æ¢ä¸ºå¯ä¿å­˜æ ¼å¼, cpu()æœ€ç»ˆè½¬è½½ä½ç½®
                # ä¿ç•™é¢„è®¡ç®—ç‰¹å¾,åç»­æ–¹ä¾¿è°ƒç”¨
                features.append(mel.cpu().detach().numpy())  # æ·»åŠ  .detach()
                labels.append(label)
                
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡æ ·æœ¬ {i}: {e}")
                continue
            
        # ä¿å­˜ç‰¹å¾
        features_array = np.stack(features).astype(np.float32)
        labels_array = np.array(labels)
    
        features_path = os.path.join(save_dir, f"features_{suffix}.npy")
        labels_path = os.path.join(save_dir, f"labels_{suffix}.npy")
        
        np.save(features_path, features_array)
        np.save(labels_path, labels_array)
        
        print(f"âœ… é¢„è®¡ç®—å®Œæˆ: {len(features_array)} æ ·æœ¬")
        return features_path, labels_path
    

# ==================== æ•°æ®é›†ç±» ====================
class PrecomputedTrainDataset(Dataset):
    """
    é¢„è®¡ç®—è®­ç»ƒæ•°æ®é›†ï¼ˆåŒ…å«å®æ—¶é¢‘è°±å¢å¼ºï¼‰
    """
    
    def __init__(self, features, labels, device):  # ğŸ¯ ä¿®å¤ï¼šç›´æ¥ä¼ å…¥æ•°ç»„
        self.features = features
        self.labels = labels
        self.device = device
        # ğŸ¯ è®­ç»ƒæ—¶åº”ç”¨é¢‘è°±å¢å¼º
        self.augmentor = CombinedAugmentation(
            sample_rate=Config.SAMPLE_RATE, 
            device=device,
            deterministic=False,  # è®­ç»ƒæ—¶ç”¨éšæœºå¢å¼º
            audio_augment=False,
            spec_augment=True     # æ˜ç¡®å¯ç”¨é¢‘è°±å¢å¼º
        )
        
        print(f"ğŸ“Š åŠ è½½é¢„è®¡ç®—è®­ç»ƒç‰¹å¾: {self.features.shape}")

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        x = torch.tensor(self.features[idx], dtype=torch.float32)
        
        # ç¡®ä¿è¾“å…¥æ˜¯3D: [1, n_mels, time]
        x = self._ensure_3d(x)
        
        # ğŸ¯ åº”ç”¨é¢‘è°±å¢å¼ºï¼ˆåœ¨GPUä¸Šï¼‰
        x = self.augmentor(x)
        
        y = int(self.labels[idx])
        return x, y
    
    def _ensure_3d(self, x):
        """ç¡®ä¿è¾“å…¥ä¸º3Då¼ é‡"""
        if x.ndim == 4:
            if x.shape[0] == 1 and x.shape[1] == 1:
                x = x.squeeze(0)
            else:
                x = x[0]
        if x.ndim == 2:
            x = x.unsqueeze(0)
        return x

class PrecomputedEvalDataset(Dataset):
    """é¢„è®¡ç®—è¯„ä¼°æ•°æ®é›†ï¼ˆæ— å¢å¼ºï¼‰"""
    
    def __init__(self, features, labels, device):  # ğŸ¯ ä¿®å¤ï¼šç›´æ¥ä¼ å…¥æ•°ç»„
        self.features = features
        self.labels = labels
        self.device = device
        print(f"ğŸ“Š åŠ è½½é¢„è®¡ç®—è¯„ä¼°ç‰¹å¾: {self.features.shape}")

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        x = torch.tensor(self.features[idx], dtype=torch.float32)
        x = self._ensure_3d(x)
        y = int(self.labels[idx])
        return x, y
    
    def _ensure_3d(self, x):
        """ç¡®ä¿è¾“å…¥ä¸º3Då¼ é‡"""
        if x.ndim == 4:
            if x.shape[0] == 1 and x.shape[1] == 1:
                x = x.squeeze(0)
            else:
                x = x[0]
        if x.ndim == 2:
            x = x.unsqueeze(0)
        return x

# ==================== æ•°æ®åŠ è½½å™¨ ====================
class DataLoaderFactory:
    """æ•°æ®åŠ è½½å™¨å·¥å‚"""
    
    @staticmethod
    def create_loader(dataset, batch_size, shuffle=True):
        return DataLoader(
            dataset, 
            batch_size=batch_size, 
            shuffle=shuffle, 
            drop_last=True, 
            num_workers=0,  # å•è¿›ç¨‹
            pin_memory=True  # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
        )

# ==================== è®­ç»ƒæ¨¡å— ====================
class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨"""
    
    def __init__(self, model, train_loader, val_loader, test_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.device = Config.DEVICE
        
    def train_single_epoch(self, criterion, optimizer, scaler, scheduler, epoch_desc):
        """è®­ç»ƒå•ä¸ªepoch"""

        # PyTorchçš„åˆ‡æ¢åˆ°è®­ç»ƒçš„æŒ‡ä»¤
        self.model.train()
        total_loss, correct, total = 0, 0, 0
        
        batch_pbar = tqdm(self.train_loader, desc=epoch_desc, leave=False)

        for batch_idx, (x, y) in enumerate(batch_pbar):
            x = x.to(self.device, non_blocking=True)
            y = y.to(self.device, non_blocking=True)
            
            optimizer.zero_grad()
            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):
                pred = self.model(x)
                loss = criterion(pred, y)
            
            # mixed precision grad management
            scaler.scale(loss).backward()   # grad squeeze -> transfer(auto finish in GPU)
            scaler.step(optimizer)          # unsqueeze
            scaler.update()                 # update
            
            # å­¦ä¹ ç‡è°ƒåº¦
            if scheduler is not None:
                current_lr = scheduler.get_last_lr()[0] 
                scheduler.step()
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_loss += loss.item()   # loss_value = loss.item()  total_loss += loss_value
            _, predicted = pred.max(dim=1)
            batch_correct = predicted.eq(y).sum().item()
            correct += batch_correct
            total += y.size(dim=0)
            
            # æ›´æ–°è¿›åº¦æ¡
            batch_acc = 100 * batch_correct / y.size(0)
            current_lr = current_lr if scheduler else optimizer.param_groups[0]['lr']
            # instant print
            batch_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'BatchAcc': f'{batch_acc:.1f}%',
                'LR': f'{current_lr:.2e}'
            })
        
        return total_loss / len(self.train_loader), 100 * correct / total
    
    def validate(self, criterion):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss, correct, total = 0, 0, 0
        
        with torch.no_grad():
            for x, y in self.val_loader:
                x = x.to(self.device, non_blocking=True)
                y = y.to(self.device, non_blocking=True)
                
                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):
                    pred = self.model(x)
                    loss = criterion(pred, y)
                
                total_loss += loss.item()
                _, predicted = pred.max(dim=1)
                correct += predicted.eq(y).sum().item()
                total += y.size(dim=0)
        
        return total_loss / len(self.val_loader), 100 * correct / total
    
    def test(self, criterion):
        """æµ‹è¯•æ¨¡å‹"""
        self.model.eval()
        total_loss, correct, total = 0, 0, 0
        
        with torch.no_grad():
            for x, y in self.test_loader:
                x = x.to(self.device, non_blocking=True)
                y = y.to(self.device, non_blocking=True)
                
                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):
                    pred = self.model(x)
                    loss = criterion(pred, y)
                
                total_loss += loss.item()
                _, predicted = pred.max(1)
                correct += predicted.eq(y).sum().item()
                total += y.size(0)
        
        return total_loss / len(self.test_loader), 100 * correct / total

    def train(self, epochs=120, patience=10):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        # æŸå¤±å‡½æ•°è®¡ç®—-åŸºäºæˆç†Ÿçš„äº¤å‰ç†µç†è®º
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.AdamW(
                                    self.model.parameters(), 
                                    lr=Config.LEARNING_RATE, 
                                    weight_decay=Config.WEIGHT_DECAY
                                    )
        scaler = torch.amp.GradScaler()
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = torch.optim.lr_scheduler.OneCycleLR(
            optimizer,
            max_lr=Config.LEARNING_RATE * Config.MAX_LR_FACTOR,
            epochs=epochs,
            steps_per_epoch=len(self.train_loader),
            pct_start=Config.WARMUP_RATIO,
            div_factor=Config.INIT_DIV_FACTOR,
            final_div_factor=Config.FINAL_DIV_FACTOR
        )

        best_acc, epochs_no_improve = 0, 0
        
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ | Epochs: {epochs} | å­¦ä¹ ç‡: {Config.LEARNING_RATE}")
        print(f"ğŸ”¥ ä½¿ç”¨OneCycleLR: warmup={Config.WARMUP_RATIO*100}%")
        print(f"ğŸ¯ å¢å¼ºç­–ç•¥: é¢„è®¡ç®—éŸ³é¢‘å¢å¼ºç‰¹å¾ + è®­ç»ƒæ—¶å®æ—¶é¢‘è°±å¢å¼º")

        epoch_pbar = tqdm(range(epochs), desc="è®­ç»ƒè¿›åº¦", leave=True)
        
        for epoch in epoch_pbar:
            epoch_desc = f"Epoch {epoch+1:02d}/{epochs}"
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_single_epoch(
                criterion, optimizer, scaler, scheduler, epoch_desc
            )
            
            # éªŒè¯å’Œæµ‹è¯•
            val_loss, val_acc = self.validate(criterion)
            test_loss, test_acc = self.test(criterion)
            
            # æ›´æ–°è¿›åº¦æ¡
            current_lr = scheduler.get_last_lr()[0]
            epoch_pbar.set_postfix({
                'Train': f'{train_acc:.1f}%',
                'Val': f'{val_acc:.1f}%', 
                'Test': f'{test_acc:.1f}%',
                'LR': f'{current_lr:.2e}'
            })
            
            # æ‰“å°è¯¦ç»†ç»“æœ
            print(f"\nEpoch {epoch+1:02d}: Train {train_acc:.2f}% | Val {val_acc:.2f}% | Test {test_acc:.2f}% | LR {current_lr:.2e} | LOSS {train_loss:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                epochs_no_improve = 0
                torch.save(self.model.state_dict(), Config.BEST_MODEL_PATH)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ | Val Acc: {best_acc:.2f}%")
            else:
                epochs_no_improve += 1
                if epochs_no_improve >= patience:
                    print(f"ğŸ›‘ æ—©åœè§¦å‘ | æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%")
                    break
                
        return Config.BEST_MODEL_PATH

# ==================== ä¸»ç¨‹åº ====================
def main():
    # åˆå§‹åŒ–é…ç½®
    print("ğŸ¯ åˆå§‹åŒ–é…ç½®...")
    label_mapping = {tag: idx for idx, tag in enumerate(Config.TOP10_TAGS)}
    num_classes = len(label_mapping)
    print(f"ğŸ”¢ æ ‡ç­¾æ˜ å°„: {label_mapping}")
    
    # æ¸…ç†å¹¶åˆ›å»ºé¢„è®¡ç®—ç›®å½•
    if os.path.exists(Config.PRECOMPUTE_DIR):
        shutil.rmtree(Config.PRECOMPUTE_DIR)
        print("ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„é¢„è®¡ç®—æ–‡ä»¶")
    os.makedirs(Config.PRECOMPUTE_DIR, exist_ok=True)
    print("ğŸ“ åˆ›å»ºæ–°çš„é¢„è®¡ç®—ç›®å½•")
    
    # ğŸ¯ åˆ›å»ºå®Œæ•´æ•°æ®é›†ï¼ˆéŸ³é¢‘å¢å¼ºï¼‰
    print("ğŸ”§ åˆ›å»ºå®Œæ•´æ•°æ®é›†...")
    full_dataset = EmotionSoundDataset(
        annotations_file=Config.ANNOTATIONS_FILE,
        audio_dir=Config.AUDIO_DIR,
        target_sample_rate=Config.SAMPLE_RATE,
        num_samples=Config.NUM_SAMPLES,
        device='cpu',
        use_log_mel=True,
        top_n_classes=10,
        augment=True,                            # âœ… å¯ç”¨å¢å¼ºæ€»å¼€å…³
        audio_augment=True,                      # âœ… å¯ç”¨éŸ³é¢‘å¢å¼º
        spec_augment=False,
        deterministic_augment=True,
        augment_seed=42
    )
    
    # é¢„è®¡ç®—å®Œæ•´æ•°æ®é›†
    full_features_path, full_labels_path = FeaturePrecomputer.precompute_features(
        full_dataset, 
        Config.PRECOMPUTE_DIR, 
        "full"
    )

    # ğŸ¯ åŠ è½½é¢„è®¡ç®—æ•°æ®
    full_features = np.load(full_features_path)
    full_labels = np.load(full_labels_path)
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(full_labels)}")

    # åˆ†å±‚æŠ½æ ·åˆ’åˆ†
    print("ğŸ“Š è¿›è¡Œåˆ†å±‚æŠ½æ ·åˆ’åˆ†...")
    
    # ç¬¬ä¸€æ¬¡åˆ’åˆ†ï¼šè®­ç»ƒé›† vs (éªŒè¯+æµ‹è¯•é›†)
    X_train, X_temp, y_train, y_temp = train_test_split(
        full_features, 
        full_labels, 
        test_size=0.3, 
        stratify=full_labels,
        random_state=42
    )
    
    # ç¬¬äºŒæ¬¡åˆ’åˆ†ï¼šéªŒè¯é›† vs æµ‹è¯•é›†
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, 
        y_temp,
        test_size=0.5,
        stratify=y_temp,
        random_state=42
    )
    
    print(f"âœ… åˆ†å±‚æŠ½æ ·å®Œæˆ: è®­ç»ƒé›† {len(y_train)} | éªŒè¯é›† {len(y_val)} | æµ‹è¯•é›† {len(y_test)}")
    
    # ğŸ¯ åˆ›å»ºæœ€ç»ˆæ•°æ®é›† - ç›´æ¥ä¼ å…¥åˆ’åˆ†åçš„æ•°ç»„
    print("ğŸ”§ åˆ›å»ºæœ€ç»ˆæ•°æ®é›†...")
    train_dataset = PrecomputedTrainDataset(X_train, y_train, Config.DEVICE)
    val_dataset = PrecomputedEvalDataset(X_val, y_val, Config.DEVICE)
    test_dataset = PrecomputedEvalDataset(X_test, y_test, Config.DEVICE)

    print(f"ğŸ¯ æœ€ç»ˆæ•°æ®é›†: è®­ç»ƒé›† {len(train_dataset)} | éªŒè¯é›† {len(val_dataset)} | æµ‹è¯•é›† {len(test_dataset)}")

    # ğŸ¯ æ•°æ®éªŒè¯
    print("=== æ•°æ®åˆ’åˆ†éªŒè¯ ===")
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}") 
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")
    print(f"è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(train_dataset.labels)}")
    print(f"éªŒè¯é›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(val_dataset.labels)}")
    print(f"æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(test_dataset.labels)}")

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoaderFactory.create_loader(train_dataset, Config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoaderFactory.create_loader(val_dataset, Config.BATCH_SIZE, shuffle=False)
    test_loader = DataLoaderFactory.create_loader(test_dataset, Config.BATCH_SIZE, shuffle=False)
    
    # æµ‹è¯•æ•°æ®å½¢çŠ¶
    for x, y in train_loader:
        print(f"ğŸ” è®­ç»ƒé›†Batchå½¢çŠ¶: è¾“å…¥ {x.shape} | æ ‡ç­¾ {y.shape}")
        break
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = CNNNetwork10(num_classes=num_classes).to(Config.DEVICE)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ¤– ä½¿ç”¨æ”¹è¿›ç‰ˆæ¨¡å‹ | å‚æ•°é‡: {total_params} ({total_params/1e6:.2f}M)")
    print(f"ğŸ¯ ä¼˜åŒ–æ–¹æ¡ˆ: é¢„è®¡ç®—éŸ³é¢‘å¢å¼ºç‰¹å¾ + è®­ç»ƒæ—¶å®æ—¶é¢‘è°±å¢å¼º")
    
    # å¼€å§‹è®­ç»ƒ
    trainer = ModelTrainer(model, train_loader, val_loader, test_loader)
    best_model_path = trainer.train(Config.EPOCHS, Config.PATIENCE)
    
    # æœ€ç»ˆæµ‹è¯•
    model.load_state_dict(torch.load(best_model_path))
    final_test_loss, final_test_acc = trainer.test(nn.CrossEntropyLoss())
    print(f"ğŸ‰ æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {final_test_acc:.2f}%")
    print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_model_path}")

if __name__ == "__main__":
    main()